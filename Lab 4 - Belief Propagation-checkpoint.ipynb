{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Belief Propagation\n",
    "\n",
    "This lab is built around the process of identifying the fault with a coffee machine.\n",
    "\n",
    "Your task is to:\n",
    " 1. Given the structure of a graphical model for the state of a coffee machine learn the distributions from data.\n",
    " 2. Implement belief propagation, so you can evaluate the probability of each failure given the available evidence.\n",
    " 3. Identify the most probable failure for a set of broken coffee machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marking and Submission\n",
    "\n",
    "These lab exercises are marked, and contribute to your final grade. For this lab exercise there are 3 places where you are expected to enter your own code, for 15 marks overall. Every place you have to add code is indicated by\n",
    "\n",
    "`# **************************************************************** n marks`\n",
    "\n",
    "with instructions above the code block.\n",
    "\n",
    "Please submit your completed workbook using Moodle before 5pm on the 28th November 2018. The workbook you submit must be an `.ipynb` file, which is saved into the directory you're running Jupyter; alternatively you can download it from the menu above using `File -> Download As -> Notebook (.ipynb)`. Remember to save your work regularly (Save and checkpoint in the File menu, the icon of a floppy disk, or Ctrl-S); the version you submit should have all code blocks showing the results (if any) of execution below them. You will normally receive feedback within a week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import zipfile\n",
    "import io\n",
    "import csv\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coffee Machine Data Set\n",
    "\n",
    "You can download from moodle a zip file that contains the data as a csv file. The below code will load the data directly from the zip file, so you don't have to unzip it.\n",
    "\n",
    "Each row of the file contains a fully observed coffee machine, with the state of every random variable. The random variables are all binary, with False represented by 0 and True represented by 1. The variables are:\n",
    "\n",
    "Failures (you're trying to detect these):  \n",
    "* 0. `he` - No electricity\n",
    "* 1. `fp` - Fried power supply unit\n",
    "* 2. `fc` - Fried circuit board  \n",
    "* 3. `wr` - Water reservoir empty\n",
    "* 4. `gs` - Group head gasket forms seal  \n",
    "* 5. `dp` - Dead pump  \n",
    "* 6. `fh` - Fried heating element  \n",
    "\n",
    "\n",
    "Mechanism (these are unobservable):  \n",
    "* 7. `pw` - Power supply unit works  \n",
    "* 8. `cb` - Circuit board works  \n",
    "* 9. `gw` - Get water out of group head   \n",
    "\n",
    "Diagnostic (these are the tests the mechanic can run - observable):\n",
    "* 10. `ls` - Room lights switch on\n",
    "* 11. `vp` - A voltage is measured across power supply unit\n",
    "* 12. `lo` - Power light switches on\n",
    "* 13. `wv` - Water visible in reservoir\n",
    "* 14. `hp` - Can hear pump\n",
    "* 15. `me` - Makes espresso\n",
    "* 16. `ta` - Makes a hot, tasty espresso\n",
    "\n",
    "For the above the number is the column number of the provided data (`dm`) and the two letter code a suggested variable name.\n",
    "\n",
    "For if you are unfamiliar with an espresso coffee machine here is a brief description of how one works (you can ignore this if you want):\n",
    "> The user puts ground coffee into a portafilter (round container with a handle and two spouts at the bottom), tamps it (compacts the coffee down), and clamps the portafilter into the group head at the front of the machine. A gasket (rubber ring) forms a seal between the portafilter and group head. A button is pressed. Water is drawn from a reservoir by a pump into a boiler. In the boiler a heating element raises the waters temperature, before the pump pushes it through the group head and into the portafilter at high pressure. The water passes through the coffee grinds and makes a tasty espresso.\n",
    "\n",
    "The graphical model showing how the variables are related is included on moodle as `coffee machine.pdf`; here it is given as conditional probabilities:\n",
    "\n",
    "Failures:\n",
    " * `P_he:` $P(\\texttt{no electricity})$\n",
    " * `P_fp:` $P(\\texttt{fried psu})$\n",
    " * `P_fc:` $P(\\texttt{fried circuit board})$\n",
    " * `P_wr:` $P(\\texttt{water reservoir empty})$\n",
    " * `P_gs:` $P(\\texttt{group head gasket seal broken})$\n",
    " * `P_dp:` $P(\\texttt{dead pump})$\n",
    " * `P_fh:` $P(\\texttt{fried heating element})$\n",
    "\n",
    "Mechanism:\n",
    " * `P_pw_he_fp:` $P(\\texttt{psu works}\\enspace|\\enspace\\texttt{no electricity},\\enspace\\texttt{fried psu})$\n",
    " * `P_cb_pw_fc:` $P(\\texttt{circuit board works}\\enspace|\\enspace\\texttt{psu works},\\enspace\\texttt{fried circuit board})$\n",
    " * `P_gw_cb_wr_dp:` $P(\\texttt{get water}\\enspace|\\enspace\\texttt{circuit board works},\\enspace\\texttt{water reservoir empty},\\enspace\\texttt{dead pump})$\n",
    "\n",
    "Diagnostic:\n",
    " * `P_ls_he:` $P(\\texttt{lights switch on}\\enspace|\\enspace\\texttt{no electricity})$\n",
    " * `P_vp_pw:` $P(\\texttt{voltage across psu}\\enspace|\\enspace\\texttt{psu works})$\n",
    " * `P_lo_cb:` $P(\\texttt{power light on}\\enspace|\\enspace\\texttt{circuit board works})$\n",
    " * `P_wv_wr:` $P(\\texttt{water visible}\\enspace|\\enspace\\texttt{water reservoir empty})$\n",
    " * `P_hp_dp:` $P(\\texttt{can hear pump}\\enspace|\\enspace\\texttt{dead pump})$\n",
    " * `P_me_gw_gs:` $P(\\texttt{makes espresso}\\enspace|\\enspace\\texttt{get water},\\enspace\\texttt{group head gasket seal broken})$\n",
    " * `P_ta_me_fh:` $P(\\texttt{tasty}\\enspace|\\enspace\\texttt{makes espresso},\\enspace\\texttt{fried heating element})$\n",
    "\n",
    "Note that while the model is close to what you may guess the probabilities are not absolute, to account for mistakes and unknown failures. For instance, the mechanic may make a mistake while brewing an espresso and erroneously conclude that the machine is broken when it is in fact awesome. The probabilities associated with each failure are not uniform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 262144 exemplars, 17 features\n",
      "     Broken machines  = 122603\n",
      "     Working machines = 139541\n"
     ]
    }
   ],
   "source": [
    "# It may prove helpful to have a mapping between the suggested variable names and\n",
    "# column indices in the provided file...\n",
    "nti = dict() # 'name to index'\n",
    "\n",
    "nti['he'] = 0\n",
    "nti['fp'] = 1\n",
    "nti['fc'] = 2\n",
    "nti['wr'] = 3\n",
    "nti['gs'] = 4\n",
    "nti['dp'] = 5\n",
    "nti['fh'] = 6\n",
    "\n",
    "nti['pw'] = 7\n",
    "nti['cb'] = 8\n",
    "nti['gw'] = 9\n",
    "\n",
    "nti['ls'] = 10\n",
    "nti['vp'] = 11\n",
    "nti['lo'] = 12\n",
    "nti['wv'] = 13\n",
    "nti['hp'] = 14\n",
    "nti['me'] = 15\n",
    "nti['ta'] = 16\n",
    "\n",
    "\n",
    "\n",
    "# Opposite to the above - index to name...\n",
    "itn = ['he', 'fp', 'fc', 'wr', 'gs', 'dp', 'fh',\n",
    "       'pw', 'cb', 'gw',\n",
    "       'ls', 'vp', 'lo', 'wv', 'hp', 'me', 'ta']\n",
    "\n",
    "\n",
    "\n",
    "# For conveniance this code loads the data from the zip file,\n",
    "# so you don't have to decompress it (takes a few seconds to run)...\n",
    "with zipfile.ZipFile('coffee_machines.zip') as zf:\n",
    "    with zf.open('coffee_machines.csv') as f:\n",
    "        sf = io.TextIOWrapper(f)\n",
    "        reader = csv.reader(sf)\n",
    "        next(reader)\n",
    "        dm = []\n",
    "        for row in reader:\n",
    "            dm.append([int(v) for v in row])\n",
    "        dm = numpy.array(dm, dtype=numpy.int8)\n",
    "\n",
    "print('Data: {} exemplars, {} features'.format(dm.shape[0], dm.shape[1]))\n",
    "print('     Broken machines  =', dm.shape[0] - dm[:,nti['ta']].sum())\n",
    "print('     Working machines =', dm[:,nti['ta']].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cb': 8,\n",
       " 'dp': 5,\n",
       " 'fc': 2,\n",
       " 'fh': 6,\n",
       " 'fp': 1,\n",
       " 'gs': 4,\n",
       " 'gw': 9,\n",
       " 'he': 0,\n",
       " 'hp': 14,\n",
       " 'lo': 12,\n",
       " 'ls': 10,\n",
       " 'me': 15,\n",
       " 'pw': 7,\n",
       " 'ta': 16,\n",
       " 'vp': 11,\n",
       " 'wr': 3,\n",
       " 'wv': 13}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Learn Model\n",
    "\n",
    "Below a set of variables to represent conditional probability distributions have been defined. They are a Bernoulli trial for each combination of conditional variables, given as $P(\\texttt{False}|...)$ in `[0,...]` and $P(\\texttt{True}|...)$ in `[1,...]` (It may be easier to think of them as boring categorical distributions).\n",
    "\n",
    "To fit a maximum likelihood model you should first use them as counters - loop over the data set and count how many of each combination exist. You must then normalise them so that the sum over axis 0 is always 1. There is an extra mark for doing the right thing and including a prior. You may want to know that the conjugate prior to the Bernoulli trial represented as $\\left[P(\\texttt{False}), P(\\texttt{True})\\right]$ is a Beta distribution; a uniform prior would be a reasonable choice (it can be argued that the expected failure probability is low, and you should adjust the first 7 variables accordingly, but given the quantity of data available it's not going to matter).\n",
    "\n",
    "Hint:\n",
    " * The use of `0=False` and `1=True` both in the dm table and in the conditional probability distributions is very deliberate.\n",
    " * Consider putting all of the variables into a list with extra information about them (such as indices from `nti`) to make your code neater.\n",
    " * If you make a mistake you could easily end up with NaN or infinity - which would break the next step. Print them out so you can check they are valid!\n",
    " * Do not write unique code for each variable - that will be hundreds of lines of code and very tedious. It's possible to get all of the marks in 7 lines of code, if you're particularly sneaky.\n",
    "\n",
    "__(4 marks)__\n",
    " * 2 marks for counting all conditions\n",
    " * 1 mark for normalising distributions\n",
    " * 1 mark for including a sensible prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A set of variables that will ultimately represent conditional probability distributions.\n",
    "# The naming convention is that P_he means P(he), or that P_ta_me_hw means P(ta|me,hw)...\n",
    "\n",
    "P_he          = numpy.zeros(2)\n",
    "P_fp          = numpy.zeros(2)\n",
    "P_fc          = numpy.zeros(2)\n",
    "P_wr          = numpy.zeros(2)\n",
    "P_gs          = numpy.zeros(2)\n",
    "P_dp          = numpy.zeros(2)\n",
    "P_fh          = numpy.zeros(2)\n",
    "\n",
    "\n",
    "P_pw_he_fp    = numpy.zeros((2,2,2))\n",
    "P_cb_pw_fc    = numpy.zeros((2,2,2))\n",
    "P_gw_cb_wr_dp = numpy.zeros((2,2,2,2))\n",
    "\n",
    "P_ls_he       = numpy.zeros((2,2))\n",
    "P_vp_pw       = numpy.zeros((2,2))\n",
    "P_lo_cb       = numpy.zeros((2,2))\n",
    "P_wv_wr       = numpy.zeros((2,2))\n",
    "P_hp_dp       = numpy.zeros((2,2))\n",
    "P_me_gw_gs    = numpy.zeros((2,2,2))\n",
    "P_ta_me_fh    = numpy.zeros((2,2,2))\n",
    "\n",
    "# It may prove conveniant to have a structure that describes the above in a computer\n",
    "# readable form, including labeling what each dimension is...\n",
    "ops = [(P_he, nti['he']),\n",
    "       (P_fp, nti['fp']),\n",
    "       (P_fc, nti['fc']),\n",
    "       (P_wr, nti['wr']),\n",
    "       (P_gs, nti['gs']),\n",
    "       (P_dp, nti['dp']),\n",
    "       (P_fh, nti['fh']),\n",
    "       (P_pw_he_fp, nti['pw'], nti['he'], nti['fp']),\n",
    "       (P_cb_pw_fc, nti['cb'], nti['pw'], nti['fc']),\n",
    "       (P_gw_cb_wr_dp, nti['gw'], nti['cb'], nti['wr'], nti['dp']),\n",
    "       (P_ls_he, nti['ls'], nti['he']),\n",
    "       (P_vp_pw, nti['vp'], nti['pw']),\n",
    "       (P_lo_cb, nti['lo'], nti['cb']),\n",
    "       (P_wv_wr, nti['wv'], nti['wr']),\n",
    "       (P_hp_dp, nti['hp'], nti['dp']),\n",
    "       (P_me_gw_gs, nti['me'], nti['gw'], nti['gs']),\n",
    "       (P_ta_me_fh, nti['ta'], nti['me'], nti['fh'])]\n",
    "\n",
    "\n",
    "\n",
    "# **************************************************************** 4 marks\n",
    "for i in range(len(ops)):\n",
    "\n",
    "    ind = ops[i][1:]\n",
    "    comb = np.argwhere(ops[i][0]==0)\n",
    "\n",
    "    for com in comb:\n",
    "    \n",
    "        com1 = com.copy()\n",
    "        com1[0] = 1 - com[0]\n",
    "    \n",
    "        num1=np.all(dm[:,ind]== com, axis=1).sum()\n",
    "        num2=np.all(dm[:,ind]== com1, axis=1).sum()\n",
    "    \n",
    "        ops[i][0][tuple(com)] = (1+num1)/(2+num2+num1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brute Force\n",
    "The below code does exactly what you want to implement for step 2, but it brute forces it. Slow and memory inefficient of course, but lets you test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99047096 0.00952904]\n",
      " [0.80056152 0.19943848]\n",
      " [0.98004547 0.01995453]\n",
      " [0.89956742 0.10043258]\n",
      " [0.95010414 0.04989586]\n",
      " [0.94968071 0.05031929]\n",
      " [0.97033714 0.02966286]\n",
      " [0.20705955 0.79294045]\n",
      " [0.22287459 0.77712541]\n",
      " [0.32884651 0.67115349]\n",
      " [0.10854219 0.89145781]\n",
      " [0.21506203 0.78493797]\n",
      " [0.22367574 0.77632426]\n",
      " [0.28021332 0.71978668]\n",
      " [0.14461369 0.85538631]\n",
      " [0.42213307 0.57786693]\n",
      " [0.46711295 0.53288705]]\n",
      "\n",
      "15 1\n",
      "[[9.99988680e-01 1.13197454e-05]\n",
      " [9.99951986e-01 4.80137278e-05]\n",
      " [9.99987176e-01 1.28242015e-05]\n",
      " [9.89199860e-01 1.08001398e-02]\n",
      " [9.94152722e-01 5.84727836e-03]\n",
      " [9.99974793e-01 2.52068210e-05]\n",
      " [9.70337140e-01 2.96628596e-02]\n",
      " [4.00504313e-05 9.99959950e-01]\n",
      " [3.23840843e-05 9.99967616e-01]\n",
      " [1.31563083e-05 9.99986844e-01]\n",
      " [9.99797579e-02 9.00020242e-01]\n",
      " [1.01366225e-02 9.89863378e-01]\n",
      " [1.06817175e-03 9.98931828e-01]\n",
      " [2.08497919e-01 7.91502081e-01]\n",
      " [9.93173565e-02 9.00682644e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [7.78509487e-02 9.22149051e-01]]\n"
     ]
    }
   ],
   "source": [
    "def brute_marginals(known):\n",
    "    \"\"\"known is a dictionary, where a random variable index existing as a key in the dictionary\n",
    "    indicates it has been observed. The value obtained using the key is the value the\n",
    "    random variable has been observed as. Returns a 17x2 matrix, such that [rv,0] is the\n",
    "    probability of random variable rv being False, [rv, 1] the probability of being True.\"\"\"\n",
    "    \n",
    "    # Calculate the full joint (please don't ask)...\n",
    "    params = []\n",
    "    for op in ops:\n",
    "        params.append(op[0])\n",
    "        params.append(op[1:])\n",
    "    params.append(range(17))\n",
    "    joint = numpy.einsum(*params)\n",
    "    #print(params)\n",
    "    # Multiply in the known states (zero out the dimensions we know it's not)...\n",
    "    for key, value in known.items():\n",
    "        print(key, value)\n",
    "        other = abs(value-1)\n",
    "        index = [slice(None)] * len(joint.shape)\n",
    "        index[key] = other\n",
    "        joint[tuple(index)] = 0.0\n",
    "        \n",
    "    # Calculate and return all marginals...\n",
    "    ret = numpy.empty((len(joint.shape), 2))\n",
    "    for row in range(ret.shape[0]):\n",
    "        ret[row,:] = numpy.einsum(joint, range(len(joint.shape)), [row])\n",
    "    \n",
    "    ret /= ret.sum(axis=1)[:,None]\n",
    "    return ret\n",
    "\n",
    "print(brute_marginals({}))\n",
    "print()\n",
    "print(brute_marginals({nti['me'] : 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Belief Propagation\n",
    "\n",
    "Your task is to write a function that take known states and calculates the marginal probability for every state of the graphical model. This will require using the _sum-product algorithm_ and passing all messages on the graph.\n",
    "\n",
    "Here is the wikipedia page for reference: https://en.wikipedia.org/wiki/Belief_propagation (not the greatest, but not horrible)\n",
    "\n",
    "Hints:\n",
    " * The order of the variables above is such that each variable is dependent only on variables that occur before it. This should save you some hassle in terms of calculating a message passing order.\n",
    " * You may want to add code before the function to prepare. This might involve creating a list of edges in the graphical model, in the order they need to be processed for instance. It can also be done with dictionaries or classes - choose whatever you are comfortable with, but spend time thinking it through first. If you get it wrong your code will get messy!\n",
    " * A good approach to recording messages is a dictionary indexed `[from, to]`\n",
    " * The easiest way to include a known value in the model is often to add/replace the unary term for that value.\n",
    " * This problem is small enough that you can brute force it - code to do so has been provided above. Do test that your implementation is correct by comparing them.\n",
    "\n",
    "__(10 marks)__\n",
    " * 3 marks for sensible data structures\n",
    " * 5 marks for sending the messages correctly\n",
    " * 2 marks for correctly calculating the marginals at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(con):\n",
    "    for i in range(len(con)):\n",
    "\n",
    "        ind = con[i][1:]\n",
    "        comb = np.argwhere(con[i][0]==0)\n",
    "\n",
    "        for com in comb:\n",
    "    \n",
    "            com1 = com.copy()\n",
    "            com1[0] = 1 - com[0]\n",
    "    \n",
    "            num1=np.all(dm[:,ind]== com, axis=1).sum()\n",
    "            num2=np.all(dm[:,ind]== com1, axis=1).sum()\n",
    "    \n",
    "            con[i][0][tuple(com)] = (1+num1)/(2+num2+num1)\n",
    "    return con\n",
    "\n",
    "P_fp_he       = numpy.zeros((2,2))\n",
    "P_fc_fp       = numpy.zeros((2,2))\n",
    "P_wr_fc       = numpy.zeros((2,2))\n",
    "P_gs_wr       = numpy.zeros((2,2))\n",
    "P_dp_gs       = numpy.zeros((2,2))\n",
    "P_fh_dp       = numpy.zeros((2,2))\n",
    "P_pw_fh       = numpy.zeros((2,2))\n",
    "P_cb_pw       = numpy.zeros((2,2))\n",
    "P_gw_cb       = numpy.zeros((2,2))\n",
    "P_ls_gw       = numpy.zeros((2,2))\n",
    "P_vp_ls       = numpy.zeros((2,2))\n",
    "P_lo_vp       = numpy.zeros((2,2))\n",
    "P_wv_lo       = numpy.zeros((2,2))\n",
    "P_hp_wv       = numpy.zeros((2,2))\n",
    "P_me_hp       = numpy.zeros((2,2))\n",
    "P_ta_me       = numpy.zeros((2,2))\n",
    "\n",
    "P_he = numpy.zeros(2)\n",
    "P_fp = numpy.zeros(2)\n",
    "P_fc = numpy.zeros(2)\n",
    "P_wr = numpy.zeros(2)\n",
    "P_gs = numpy.zeros(2)\n",
    "P_dp = numpy.zeros(2)\n",
    "P_fh = numpy.zeros(2)\n",
    "P_pw = numpy.zeros(2) \n",
    "P_cb = numpy.zeros(2)   \n",
    "P_gw = numpy.zeros(2)  \n",
    "P_ls = numpy.zeros(2)            \n",
    "P_vp = numpy.zeros(2)               \n",
    "P_lo = numpy.zeros(2)               \n",
    "P_wv = numpy.zeros(2)      \n",
    "P_hp = numpy.zeros(2)\n",
    "P_me = numpy.zeros(2)\n",
    "P_ta = numpy.zeros(2) \n",
    "\n",
    "unary = [(P_he, nti['he']),\n",
    "         (P_fp, nti['fp']),\n",
    "         (P_fc, nti['fc']),\n",
    "         (P_wr, nti['wr']),\n",
    "         (P_gs, nti['gs']),\n",
    "         (P_dp, nti['dp']),\n",
    "         (P_fh, nti['fh']),\n",
    "         (P_pw, nti['pw']),\n",
    "         (P_cb, nti['cb']),\n",
    "         (P_gw, nti['gw']),\n",
    "         (P_ls, nti['ls']),\n",
    "         (P_vp, nti['vp']),\n",
    "         (P_lo, nti['lo']),\n",
    "         (P_wv, nti['wv']),\n",
    "         (P_hp, nti['hp']),\n",
    "         (P_me, nti['me']),\n",
    "         (P_ta, nti['ta'])\n",
    "      ]\n",
    "\n",
    "con = [(P_fp_he, nti['fp'],nti['he']),\n",
    "       (P_fc_fp, nti['fc'],nti['hp']),\n",
    "       (P_wr_fc, nti['wr'],nti['fc']),       \n",
    "       (P_gs_wr, nti['gs'],nti['wr']),       \n",
    "       (P_dp_gs, nti['dp'],nti['gs']),      \n",
    "       (P_fh_dp, nti['fh'],nti['dp']),       \n",
    "       (P_pw_fh, nti['pw'],nti['fh']),       \n",
    "       (P_cb_pw, nti['cb'],nti['pw']),\n",
    "       (P_gw_cb, nti['gw'],nti['cb']),       \n",
    "       (P_ls_gw, nti['ls'],nti['gw']),\n",
    "       (P_vp_ls, nti['vp'],nti['ls']),   \n",
    "       (P_vp_pw, nti['vp'],nti['pw']), \n",
    "       (P_lo_vp, nti['lo'],nti['vp']),       \n",
    "       (P_wv_lo, nti['wv'],nti['lo']),       \n",
    "       (P_hp_wv, nti['hp'],nti['wv']),       \n",
    "       (P_me_hp, nti['me'],nti['hp']),       \n",
    "       (P_ta_me, nti['ta'],nti['me'])\n",
    "      ]\n",
    "\n",
    "unary = prob(unary)\n",
    "con   = prob(con)\n",
    "\n",
    "#Graph Structure\n",
    "graph = [(P_he, P_fp_he ),\n",
    "         (P_fp, P_fc_fp ),\n",
    "         (P_fc, P_wr_fc ),\n",
    "         (P_wr, P_gs_wr ),\n",
    "         (P_dp, P_dp_gs ),\n",
    "         (P_fh, P_fh_dp ),\n",
    "         (P_pw, P_cb_pw, P_he, P_fp, P_pw_he_fp),\n",
    "         (P_cb, P_gw_cb, P_pw, P_fc, P_cb_pw_fc),\n",
    "         (P_gw, P_ls_gw, P_cb, P_wr, P_dp, P_gw_cb_wr_dp),\n",
    "         (P_ls, P_vp_ls, P_he, P_ls_he ),\n",
    "         (P_vp, P_vp_pw, P_pw, P_vp_pw ),\n",
    "         (P_lo, P_wv_lo, P_cb, P_lo_cb ),\n",
    "         (P_wv, P_hp_wv, P_wr, P_wv_wr ),\n",
    "         (P_hp, P_me_hp, P_dp, P_hp_dp ),\n",
    "         (P_me, P_ta_me, P_gw, P_gs, P_me_gw_gs ),\n",
    "         (P_ta, P_me, P_fh, P_ta_me_fh) \n",
    "        ]\n",
    "\n",
    "       \n",
    "\n",
    "def marginals(known):\n",
    "    \"\"\"known is a dictionary, where a random variable index existing as a key in the dictionary\n",
    "    indicates it has been observed. The value obtained using the key is the value the\n",
    "    random variable has been observed as. Returns a 17x2 matrix, such that [rv,0] is the\n",
    "    probability of random variable rv being False, [rv, 1] the probability of being True.\"\"\"\n",
    "    \n",
    "    # **************************************************************** 10 marks\n",
    "    pass\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond(con):\n",
    "    for i in range(len(con)):\n",
    "\n",
    "        ind = con[i][1:]\n",
    "        comb = np.argwhere(con[i][0]==0)\n",
    "\n",
    "        for com in comb:\n",
    "    \n",
    "            com1 = com.copy()\n",
    "            com1[0] = 1 - com[0]\n",
    "    \n",
    "            num1=np.all(dm[:,ind]== com, axis=1).sum()\n",
    "            num2=np.all(dm[:,ind]== com1, axis=1).sum()\n",
    "    \n",
    "            con[i][0][tuple(com)] = (1+num1)/(2+num2+num1)\n",
    "    return con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97033714, 0.02966286])"
      ]
     },
     "execution_count": 1104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_fh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cond(con)\n",
    "#P_fh = np.array([0,1])\n",
    "m_Fhefp_he = P_he\n",
    "m_Fhefp_fp = numpy.einsum('b,ab->b', m_Fhefp_he, con[0][0])\n",
    "\n",
    "m_fp_Ffpfc = numpy.einsum('a,b->a',P_fp,m_Fhefp_fp)\n",
    "m_Ffpfc_fc = numpy.einsum('b,ab->b',m_fp_Ffpfc,con[1][0])\n",
    "\n",
    "m_fc_Ffcwr = numpy.einsum('a,b->a',P_fc,m_Ffpfc_fc)\n",
    "m_Ffcwr_wr = numpy.einsum('b,ab->b',m_fc_Ffcwr,con[2][0])\n",
    "\n",
    "m_wr_Fwrgs = numpy.einsum('a,b->a', P_wr, m_Ffcwr_wr)\n",
    "m_Fwrgs_gs = numpy.einsum('b,ab->b',m_wr_Fwrgs,con[3][0])\n",
    "\n",
    "m_gs_Fgsdp = numpy.einsum('a,b->a', P_gs,m_Fwrgs_gs)\n",
    "m_Fgsdp_dp = numpy.einsum('b,ab->b',m_gs_Fgsdp,con[4][0])\n",
    "\n",
    "m_dp_Fdpfh = numpy.einsum('a,b->a', P_dp,m_Fgsdp_dp)\n",
    "m_Fdpfh_fh = numpy.einsum('b,ab->b',m_dp_Fdpfh,con[5][0])\n",
    "\n",
    "m_fh_Ffhpw = numpy.einsum('a,b->a', P_fh,m_Fdpfh_fh)\n",
    "m_Ffhpw_pw = numpy.einsum('b,ab->b',m_fh_Ffhpw,con[6][0])\n",
    "\n",
    "m_Fhe_Ffp    = numpy.einsum('a,b', P_he, P_fp)\n",
    "m_Fpwhefp_pw = numpy.einsum('bc,abc->a', m_Fhe_Ffp, P_pw_he_fp)\n",
    "m_pw_Fpwcb   = numpy.einsum('a,b->a', m_Fpwhefp_pw, m_Ffhpw_pw)\n",
    "m_pw_Fpwcb   = numpy.einsum('a,b->b', m_pw_Fpwcb, P_pw)\n",
    "\n",
    "m_Fpwcb_cb = numpy.einsum('b,ab->b',m_pw_Fpwcb,con[7][0])\n",
    "m_Fpw_Ffc    = numpy.einsum('a,b', P_pw, P_fc)\n",
    "m_Fcbpwfc_cb = numpy.einsum('bc,abc->a', m_Fpw_Ffc, P_cb_pw_fc)\n",
    "m_cb_Fcbgw   = numpy.einsum('a,b->a', m_Fcbpwfc_cb, m_Fpwcb_cb)\n",
    "m_cb_Fcbgw   = numpy.einsum('a,b->b', m_cb_Fcbgw, P_cb)\n",
    "\n",
    "m_Fcbgw_gw     = numpy.einsum('b,ab->b',m_cb_Fcbgw,con[8][0])\n",
    "m_Fcb_Fwr_Fdp  = numpy.einsum('a,b,c', P_cb, P_wr, P_dp)\n",
    "m_Fgwcbwrdp_gw = numpy.einsum('bcd,abcd->a', m_Fcb_Fwr_Fdp,P_gw_cb_wr_dp)\n",
    "m_gw_Fgwls     = numpy.einsum('a,b->a',m_Fgwcbwrdp_gw,m_Fcbgw_gw)\n",
    "m_gw_Fgwls     = numpy.einsum('a,b->b',m_gw_Fgwls,P_gw)\n",
    "\n",
    "m_Fgwls_ls = numpy.einsum('b,ab->b',m_gw_Fgwls,con[9][0])\n",
    "m_Flshe_ls = numpy.einsum('b,ab->a', P_he, P_ls_he)\n",
    "m_ls_Flsvp = numpy.einsum('a,b->a',m_Flshe_ls,m_Fgwls_ls)\n",
    "m_ls_Flsvp = numpy.einsum('a,b->b',m_ls_Flsvp,P_ls)\n",
    "\n",
    "m_Flsvp_vp  = numpy.einsum('b,ab->b',m_ls_Flsvp,con[10][0])\n",
    "m_Fpwvp_vp  = numpy.einsum('b,ab->a', P_pw, P_vp_pw)\n",
    "m_vp_Fvplo  = numpy.einsum('a,b->a',m_Fpwvp_vp,m_Flsvp_vp)\n",
    "m_vp_Fvplo  = numpy.einsum('a,b->b',m_vp_Fvplo,P_vp)\n",
    "\n",
    "m_Fvplo_lo  = numpy.einsum('b,ab->b',m_vp_Fvplo,con[11][0])\n",
    "m_Flocb_lo  = numpy.einsum('b,ab->a', P_cb, P_lo_cb)\n",
    "m_lo_Flowv  = numpy.einsum('a,b->a',m_Flocb_lo,m_Fvplo_lo)\n",
    "m_lo_Flowv  = numpy.einsum('a,b->b',m_lo_Flowv,P_lo)\n",
    "\n",
    "m_Flowv_wv  = numpy.einsum('b,ab->b',m_lo_Flowv,con[12][0])\n",
    "m_Fwvwr_wv  = numpy.einsum('b,ab->a', P_wr, P_wv_wr)\n",
    "m_wv_Fwvhp  = numpy.einsum('a,b->a',m_Fwvwr_wv,m_Flowv_wv)\n",
    "m_wv_Fwvhp  = numpy.einsum('a,b->b',m_wv_Fwvhp,P_wv)\n",
    "\n",
    "m_Fwvhp_hp  = numpy.einsum('b,ab->b',m_wv_Fwvhp,con[12][0])\n",
    "m_Fhpdp_hp  = numpy.einsum('b,ab->a', P_dp, P_hp_dp)\n",
    "m_hp_Fhpme  = numpy.einsum('a,b->a',m_Fhpdp_hp,m_Fwvhp_hp)\n",
    "m_hp_Fhpme  = numpy.einsum('a,b->b',m_hp_Fhpme,P_hp)\n",
    "\n",
    "m_Fhpme_me   = numpy.einsum('b,ab->b',m_hp_Fhpme,con[13][0])\n",
    "m_Fgw_Fgs    = numpy.einsum('a,b', P_gw, P_gs)\n",
    "m_Fmegwgs_me = numpy.einsum('bc,abc->a', m_Fgw_Fgs, P_me_gw_gs)\n",
    "m_me_F_meta  = numpy.einsum('a,b->a',m_Fmegwgs_me,m_Fhpme_me)\n",
    "m_me_F_meta  = numpy.einsum('a,b->b',m_me_F_meta,P_me)\n",
    "\n",
    "m_Fme_Ffh    = numpy.einsum('a,b', P_me, P_fh)\n",
    "m_Ftamefh_ta = numpy.einsum('bc,abc->a', m_Fme_Ffh, P_ta_me_fh)\n",
    "\n",
    "ret = np.array([\n",
    " m_he_Fhefp,\n",
    " m_fp_Ffpfc,\n",
    " m_fc_Ffcwr,\n",
    " m_wr_Fwrgs,\n",
    " m_gs_Fgsdp,\n",
    " m_dp_Fdpfh,\n",
    " m_fh_Ffhpw,\n",
    " m_pw_Fpwcb,\n",
    " m_cb_Fcbgw,\n",
    " m_gw_Fgwls,\n",
    " m_ls_Flsvp,\n",
    " m_vp_Fvplo,\n",
    " m_lo_Flowv,\n",
    " m_wv_Fwvhp,\n",
    " m_hp_Fhpme,\n",
    " m_me_F_meta,\n",
    " m_Ftamefh_ta,\n",
    "])\n",
    "ret /= ret.sum(axis=1)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99047096, 0.00952904],\n",
       "       [0.80056152, 0.19943848],\n",
       "       [0.98004547, 0.01995453],\n",
       "       [0.89956742, 0.10043258],\n",
       "       [0.95010414, 0.04989586],\n",
       "       [0.94968071, 0.05031929],\n",
       "       [0.97033714, 0.02966286],\n",
       "       [0.20699534, 0.79300466],\n",
       "       [0.22294447, 0.77705553],\n",
       "       [0.32961022, 0.67038978],\n",
       "       [0.10854257, 0.89145743],\n",
       "       [0.21499851, 0.78500149],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.14461407, 0.85538593],\n",
       "       [0.42276823, 0.57723177],\n",
       "       [0.46769865, 0.53230135]])"
      ]
     },
     "execution_count": 1111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.90470959e-01, 9.52904107e-03],\n",
       "       [8.00561519e-01, 1.99438481e-01],\n",
       "       [9.80045471e-01, 1.99545292e-02],\n",
       "       [8.99567417e-01, 1.00432583e-01],\n",
       "       [9.50104140e-01, 4.98958596e-02],\n",
       "       [9.49680712e-01, 5.03192877e-02],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [2.07059547e-01, 7.92940453e-01],\n",
       "       [2.22874588e-01, 7.77125412e-01],\n",
       "       [3.28846512e-01, 6.71153488e-01],\n",
       "       [1.08542188e-01, 8.91457812e-01],\n",
       "       [2.15062033e-01, 7.84937967e-01],\n",
       "       [2.23675738e-01, 7.76324262e-01],\n",
       "       [2.80213317e-01, 7.19786683e-01],\n",
       "       [1.44613692e-01, 8.55386308e-01],\n",
       "       [4.22133073e-01, 5.77866927e-01],\n",
       "       [9.99742983e-01, 2.57016897e-04]])"
      ]
     },
     "execution_count": 1082,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brute_marginals({nti['fh'] : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07785857, 0.85643306])"
      ]
     },
     "execution_count": 818,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_Fme_Ffh    = numpy.einsum('a,b', np.array([0,1]), P_fh)\n",
    "m_Ftamefh_ta = numpy.einsum('bc,abc->a', m_Fme_Ffh, P_ta_me_fh)\n",
    "m_ta_Fmeta   = m_Ftamefh_ta#numpy.einsum('a,b->a', m_Ftamefh_ta, P_ta)\n",
    "\n",
    "m_Fmeta_ta   = numpy.einsum('b,ab->b',m_me_F_meta,con[14][0])\n",
    "\n",
    "g_ta = numpy.einsum('a,b->b',m_Fmeta_ta,m_Ftamefh_ta)\n",
    "\n",
    "m_Fmeta_me   = numpy.einsum('a,ab->b', m_ta_Fmeta, P_ta_me)\n",
    "m_Fmeta_me\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 824,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(P_ta*m_Ftamefh_ta*m_Fmeta_ta*np.array([0,1]))/(P_ta*m_Ftamefh_ta*m_Fmeta_ta*np.array([0,1])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_Fme_Ffh    = numpy.einsum('a,b,c', np.array([0,1]), P_fh, P_ta)\n",
    "m_Ftamefh_ta = numpy.einsum('abc,abc->a', m_Fme_Ffh, P_ta_me_fh)\n",
    "m_ta_Fmeta   = m_Ftamefh_ta\n",
    "m_Ftamefh_ta/=m_Ftamefh_ta.sum()\n",
    "m_Ftamefh_ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.99988680e-01, 1.13197454e-05],\n",
       "       [9.99951986e-01, 4.80137278e-05],\n",
       "       [9.99987176e-01, 1.28242015e-05],\n",
       "       [9.89199860e-01, 1.08001398e-02],\n",
       "       [9.94152722e-01, 5.84727836e-03],\n",
       "       [9.99974793e-01, 2.52068210e-05],\n",
       "       [9.70337140e-01, 2.96628596e-02],\n",
       "       [4.00504313e-05, 9.99959950e-01],\n",
       "       [3.23840843e-05, 9.99967616e-01],\n",
       "       [1.31563083e-05, 9.99986844e-01],\n",
       "       [9.99797579e-02, 9.00020242e-01],\n",
       "       [1.01366225e-02, 9.89863378e-01],\n",
       "       [1.06817175e-03, 9.98931828e-01],\n",
       "       [2.08497919e-01, 7.91502081e-01],\n",
       "       [9.93173565e-02, 9.00682644e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [7.78509487e-02, 9.22149051e-01]])"
      ]
     },
     "execution_count": 788,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brute_marginals({nti['me'] : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99047096, 0.00952904],\n",
       "       [0.80056152, 0.19943848],\n",
       "       [0.98004547, 0.01995453],\n",
       "       [0.89956742, 0.10043258],\n",
       "       [0.95010414, 0.04989586],\n",
       "       [0.94968071, 0.05031929],\n",
       "       [0.97033714, 0.02966286],\n",
       "       [0.20699534, 0.79300466],\n",
       "       [0.22294447, 0.77705553],\n",
       "       [0.32961022, 0.67038978],\n",
       "       [0.10854257, 0.89145743],\n",
       "       [0.21499851, 0.78500149],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.14461407, 0.85538593],\n",
       "       [0.42276823, 0.57723177],\n",
       "       [0.46769865, 0.53230135]])"
      ]
     },
     "execution_count": 1113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond(con)\n",
    "\n",
    "#{nti['wv'] : False, nti['lo'] : True}\n",
    "P_wv = np.array([1,0])\n",
    "P_lo = np.array([0,1])\n",
    "\n",
    "m_he_Fhefp = P_he\n",
    "m_Fhefp_fp = numpy.einsum('b,ab->a', m_he_Fhefp, con[0][0])\n",
    "\n",
    "m_fp_Ffpfc = numpy.einsum('a,b->a',P_fp,m_Fhefp_fp)\n",
    "m_Ffpfc_fc = numpy.einsum('b,ab->a',m_fp_Ffpfc,con[1][0])\n",
    "\n",
    "m_fc_Ffcwr = numpy.einsum('a,b->a',P_fc,m_Ffpfc_fc)\n",
    "m_Ffcwr_wr = numpy.einsum('b,ab->a',m_fc_Ffcwr,con[2][0])\n",
    "\n",
    "m_wr_Fwrgs = numpy.einsum('a,b->a', P_wr, m_Ffcwr_wr)\n",
    "m_Fwrgs_gs = numpy.einsum('b,ab->a',m_wr_Fwrgs,con[3][0])\n",
    "\n",
    "m_gs_Fgsdp = numpy.einsum('a,b->a', P_gs,m_Fwrgs_gs)\n",
    "m_Fgsdp_dp = numpy.einsum('b,ab->a',m_gs_Fgsdp,con[4][0])\n",
    "\n",
    "m_dp_Fdpfh = numpy.einsum('a,b->a', P_dp,m_Fgsdp_dp)\n",
    "m_Fdpfh_fh = numpy.einsum('b,ab->a',m_dp_Fdpfh,con[5][0])\n",
    "\n",
    "m_fh_Ffhpw = numpy.einsum('a,b->a', P_fh,m_Fdpfh_fh)\n",
    "m_Ffhpw_pw = numpy.einsum('b,ab->a',m_fh_Ffhpw,con[6][0])\n",
    "\n",
    "m_Fhe_Ffp    = numpy.einsum('a,b', P_he, P_fp)\n",
    "m_Fpwhefp_pw = numpy.einsum('bc,abc->a', m_Fhe_Ffp, P_pw_he_fp)\n",
    "m_pw_Fpwcb   = numpy.einsum('a,b->a', m_Fpwhefp_pw, m_Ffhpw_pw)\n",
    "m_pw_Fpwcb   = numpy.einsum('a,b->b', m_pw_Fpwcb, P_pw)\n",
    "\n",
    "m_Fpwcb_cb = numpy.einsum('b,ab->a',m_pw_Fpwcb,con[7][0])\n",
    "m_Fpw_Ffc    = numpy.einsum('a,b', m_pw_Fpwcb, m_fc_Ffcwr)           ###related node\n",
    "m_Fcbpwfc_cb = numpy.einsum('bc,abc->a', m_Fpw_Ffc, P_cb_pw_fc)\n",
    "m_cb_Fcbgw   = numpy.einsum('a,b->b', m_Fcbpwfc_cb, m_Fpwcb_cb)\n",
    "m_cb_Fcbgw   = numpy.einsum('a,b->b', m_cb_Fcbgw, P_cb)\n",
    "\n",
    "m_Fcbgw_gw     = numpy.einsum('b,ab->a',m_cb_Fcbgw,con[8][0])\n",
    "m_Fcb_Fwr_Fdp  = numpy.einsum('a,b,c', P_cb, m_wr_Fwrgs, P_dp)\n",
    "m_Fgwcbwrdp_gw = numpy.einsum('bcd,abcd->a', m_Fcb_Fwr_Fdp,P_gw_cb_wr_dp)\n",
    "m_gw_Fgwls     = numpy.einsum('a,b->b',m_Fgwcbwrdp_gw,m_Fcbgw_gw)\n",
    "m_gw_Fgwls     = numpy.einsum('a,b->b',m_gw_Fgwls,P_gw)\n",
    "\n",
    "m_Fgwls_ls = numpy.einsum('b,ab->a',m_gw_Fgwls,con[9][0])\n",
    "m_Flshe_ls = numpy.einsum('b,ab->a', P_he, P_ls_he)\n",
    "m_ls_Flsvp = numpy.einsum('a,b->a',m_Flshe_ls,m_Fgwls_ls)\n",
    "m_ls_Flsvp = numpy.einsum('a,b->b',m_ls_Flsvp,P_ls)\n",
    "\n",
    "m_Flsvp_vp  = numpy.einsum('b,ab->a',m_ls_Flsvp,con[10][0])\n",
    "m_Fpwvp_vp  = numpy.einsum('b,ab->a', m_pw_Fpwcb, P_vp_pw)     ###related node\n",
    "m_vp_Fvplo  = numpy.einsum('a,b->a',m_Fpwvp_vp,m_Flsvp_vp)\n",
    "m_vp_Fvplo  = numpy.einsum('a,b->b',m_vp_Fvplo,P_vp)\n",
    "\n",
    "m_Fvplo_lo  = numpy.einsum('b,ab->a',m_vp_Fvplo,con[11][0])\n",
    "m_Flocb_lo  = numpy.einsum('b,ab->a', m_cb_Fcbgw, P_lo_cb)     ###related node\n",
    "m_lo_Flowv  = numpy.einsum('a,b->a',m_Flocb_lo,m_Fvplo_lo)\n",
    "m_lo_Flowv  = numpy.einsum('a,b->b',m_lo_Flowv,P_lo)\n",
    "\n",
    "m_Flowv_wv  = numpy.einsum('b,ab->a',m_lo_Flowv,con[12][0])\n",
    "m_Fwvwr_wv  = numpy.einsum('b,ab->a', m_wr_Fwrgs, P_wv_wr)\n",
    "m_wv_Fwvhp  = numpy.einsum('a,b->a',m_Fwvwr_wv,m_Flowv_wv)\n",
    "m_wv_Fwvhp  = numpy.einsum('a,b->b',m_wv_Fwvhp,P_wv)\n",
    "\n",
    "m_Fwvhp_hp  = numpy.einsum('b,ab->a',m_wv_Fwvhp,con[12][0])\n",
    "m_Fhpdp_hp  = numpy.einsum('b,ab->a', P_dp, P_hp_dp)\n",
    "m_hp_Fhpme  = numpy.einsum('a,b->a',m_Fhpdp_hp,m_Fwvhp_hp)\n",
    "m_hp_Fhpme  = numpy.einsum('a,b->b',m_hp_Fhpme,P_hp)\n",
    "\n",
    "m_Fhpme_me   = numpy.einsum('b,ab->a',m_hp_Fhpme,con[13][0])\n",
    "m_Fgw_Fgs    = numpy.einsum('a,b', m_gw_Fgwls, m_gs_Fgsdp)      ###related note\n",
    "m_Fmegwgs_me = numpy.einsum('bc,abc->a', m_Fgw_Fgs, P_me_gw_gs)\n",
    "\n",
    "m_me_F_meta  = numpy.einsum('a,b->a',m_Fmegwgs_me,m_Fhpme_me)\n",
    "m_me_F_meta  = numpy.einsum('a,b->b',m_me_F_meta,P_me)\n",
    "\n",
    "m_me_gwgs    = numpy.einsum('a,b->a', m_me_F_meta, P_me)\n",
    "m_Fme_Ffh    = numpy.einsum('a,b', m_me_gwgs, m_fh_Ffhpw)\n",
    "m_Ftamefh_ta = numpy.einsum('bc,abc->a', m_Fme_Ffh, P_ta_me_fh)\n",
    "\n",
    "ret = np.array([\n",
    " m_he_Fhefp,\n",
    " m_fp_Ffpfc,\n",
    " m_fc_Ffcwr,\n",
    " m_wr_Fwrgs,\n",
    " m_gs_Fgsdp,\n",
    " m_dp_Fdpfh,\n",
    " m_fh_Ffhpw,\n",
    " m_pw_Fpwcb,\n",
    " m_cb_Fcbgw,\n",
    " m_gw_Fgwls,\n",
    " m_ls_Flsvp,\n",
    " m_vp_Fvplo,\n",
    " m_lo_Flowv,\n",
    " m_wv_Fwvhp,\n",
    " m_hp_Fhpme,\n",
    " m_me_F_meta,\n",
    " m_Ftamefh_ta,\n",
    "])\n",
    "ret /= ret.sum(axis=1)[:,None]\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46769358, 0.53230642])"
      ]
     },
     "execution_count": 1117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_ta_F_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41475939, 0.58524061])"
      ]
     },
     "execution_count": 1114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "m_ta_F_meta  = numpy.einsum('a,b->b',m_Ftamefh_ta,P_ta)\n",
    "m_F_meta_me  = numpy.einsum('a,ab->b',m_ta_F_meta,P_ta_me) \n",
    "\n",
    "m_me_F_hpme  = numpy.einsum('a,b->b',m_Fmegwgs_me,P_me)\n",
    "m_me_F_hpme  = numpy.einsum('a,b->b',m_F_meta_me,m_me_F_hpme)\n",
    "m_F_hpme_hp  = numpy.einsum('a,ab->b',m_me_F_hpme,P_me_hp) \n",
    "\n",
    "m_me_F_hpme*m_Fhpme_me*m_ta_F_meta\n",
    "\n",
    "m_hp_F_wvhp  = numpy.einsum('a,b->b',m_Fhpdp_hp,P_hp)\n",
    "m_hp_F_wvhp  = numpy.einsum('a,b->b',m_F_hpme_hp,m_hp_F_wvhp)\n",
    "\n",
    "m_F_hpme_hp  = numpy.einsum('a,ab->b',m_me_F_hpme,P_me_hp)\n",
    "\n",
    "m_hp_F_wvhp  = numpy.einsum('a,b->b',m_F_hpme_hp,m_Fhpdp_hp)\n",
    "\n",
    "(P_hp*m_hp_F_wvhp*m_F_hpme_hp*m_Fwvhp_hp)/(P_hp*m_hp_F_wvhp*m_F_hpme_hp*m_Fwvhp_hp).sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20049136, 0.79950864])"
      ]
     },
     "execution_count": 1116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(m_me_F_hpme*m_Fhpme_me*m_ta_F_meta)/(m_me_F_hpme*m_Fhpme_me*m_ta_F_meta).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99047096, 0.00952904],\n",
       "       [0.80056152, 0.19943848],\n",
       "       [0.98004547, 0.01995453],\n",
       "       [0.89956742, 0.10043258],\n",
       "       [0.95010414, 0.04989586],\n",
       "       [0.94968071, 0.05031929],\n",
       "       [0.97033714, 0.02966286],\n",
       "       [0.20699534, 0.79300466],\n",
       "       [0.22294447, 0.77705553],\n",
       "       [0.32961022, 0.67038978],\n",
       "       [0.10854257, 0.89145743],\n",
       "       [0.21499851, 0.78500149],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.14461407, 0.85538593],\n",
       "       [0.42276823, 0.57723177],\n",
       "       [0.46769865, 0.53230135]])"
      ]
     },
     "execution_count": 1112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 False\n",
      "12 True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.99989854e-01, 1.01464022e-05],\n",
       "       [9.99976567e-01, 2.34329020e-05],\n",
       "       [9.99989634e-01, 1.03657912e-05],\n",
       "       [6.41598872e-01, 3.58401128e-01],\n",
       "       [9.50104140e-01, 4.98958596e-02],\n",
       "       [9.49680712e-01, 5.03192877e-02],\n",
       "       [9.70337140e-01, 2.96628596e-02],\n",
       "       [1.45290999e-05, 9.99985471e-01],\n",
       "       [4.91213203e-06, 9.99995088e-01],\n",
       "       [3.57451562e-01, 6.42548438e-01],\n",
       "       [9.99787023e-02, 9.00021298e-01],\n",
       "       [1.01113593e-02, 9.89888641e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.44613692e-01, 8.55386308e-01],\n",
       "       [4.46761196e-01, 5.53238804e-01],\n",
       "       [4.89823305e-01, 5.10176695e-01]])"
      ]
     },
     "execution_count": 1095,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brute_marginals({nti['wv'] : False, nti['lo'] : True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. What's broken?\n",
    "\n",
    "Simply print out what the most probable broken part of each of the below machines is. Please print it as\n",
    "`dictionary key: name of broken part`, e.g. `A: wr`. This will allow automarking to be used.\n",
    "\n",
    "If you can't get your belief propagation implementation to work feel free to use `brute_marginals` instead.\n",
    "\n",
    "__(1 mark)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repair = {}\n",
    "repair['A'] = {nti['me'] : True}\n",
    "repair['B'] = {nti['wv'] : True}\n",
    "repair['C'] = {nti['wv'] : False, nti['lo'] : True}\n",
    "repair['D'] = {nti['hp'] : False, nti['ta'] : False}\n",
    "repair['E'] = {nti['hp'] : True, nti['wv'] : True, nti['vp']: True}\n",
    "\n",
    "\n",
    "\n",
    "# **************************************************************** 1 mark\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brute_marginals(repair['E'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28021408, 0.71978592])"
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
